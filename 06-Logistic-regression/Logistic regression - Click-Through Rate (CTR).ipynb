{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Logo](http://spark-mooc.github.io/web-assets/images/CS190.1x_Banner_300.png)\n",
    "# **Click-Through Rate Prediction Lab**\n",
    "#### This lab covers the steps for creating a click-through rate (CTR) prediction pipeline.  You will work with the [Criteo Labs](http://labs.criteo.com/) dataset that was used for a recent [Kaggle competition](https://www.kaggle.com/c/criteo-display-ad-challenge).\n",
    "#### ** This lab will cover: **\n",
    "+  ####*Part 1:* Featurize categorical data using one-hot-encoding (OHE)\n",
    "+  ####*Part 2:* Construct an OHE dictionary\n",
    "+  ####*Part 3:* Parse CTR data and generate OHE features\n",
    " + #### *Visualization 1:* Feature frequency\n",
    "+  ####*Part 4:* CTR prediction and logloss evaluation\n",
    " + #### *Visualization 2:* ROC curve\n",
    "+  ####*Part 5:* Reduce feature dimension via feature hashing\n",
    " + #### *Visualization 3:* Hyperparameter heat map\n",
    " \n",
    "#### Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labVersion = 'cs190_week4_v_1_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Featurize categorical data using one-hot-encoding **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) One-hot-encoding **\n",
    "#### We would like to develop code to convert categorical features to numerical ones, and to build intuition, we will work with a sample unlabeled dataset with three data points, with each data point representing an animal. The first feature indicates the type of animal (bear, cat, mouse); the second feature describes the animal's color (black, tabby); and the third (optional) feature describes what the animal eats (mouse, salmon).\n",
    "#### In a one-hot-encoding (OHE) scheme, we want to represent each tuple of `(featureID, category)` via its own binary feature.  We can do this in Python by creating a dictionary that maps each tuple to a distinct integer, where the integer corresponds to a binary feature. To start, manually enter the entries in the OHE dictionary associated with the sample dataset by mapping the tuples to consecutive integers starting from zero,  ordering the tuples first by featureID and next by category.\n",
    "#### Later in this lab, we'll use OHE dictionaries to transform data points into compact lists of features that can be used in machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data for manual OHE\n",
    "# Note: the first data point does not include any value for the optional third feature\n",
    "sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]\n",
    "sampleDataRDD = sc.parallelize([sampleOne, sampleTwo, sampleThree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOHEDictManual = {}\n",
    "sampleOHEDictManual[(0,'bear')] = 0 #<FILL IN>\n",
    "sampleOHEDictManual[(0,'cat')] = 1 # <FILL IN>\n",
    "sampleOHEDictManual[(0,'mouse')] = 2 # <FILL IN>\n",
    "sampleOHEDictManual[(1,'black')] = 3\n",
    "sampleOHEDictManual[(1,'tabby')] = 4\n",
    "sampleOHEDictManual[(2,'mouse')] = 5\n",
    "sampleOHEDictManual[(2,'salmon')] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST One-hot-encoding (1a)\n",
    "from test_helper import Test\n",
    "\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(0,'bear')],\n",
    "                        'b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
    "                        \"incorrect value for sampleOHEDictManual[(0,'bear')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(0,'cat')],\n",
    "                        '356a192b7913b04c54574d18c28d46e6395428ab',\n",
    "                        \"incorrect value for sampleOHEDictManual[(0,'cat')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(0,'mouse')],\n",
    "                        'da4b9237bacccdf19c0760cab7aec4a8359010b0',\n",
    "                        \"incorrect value for sampleOHEDictManual[(0,'mouse')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(1,'black')],\n",
    "                        '77de68daecd823babbb58edb1c8e14d7106e83bb',\n",
    "                        \"incorrect value for sampleOHEDictManual[(1,'black')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(1,'tabby')],\n",
    "                        '1b6453892473a467d07372d45eb05abc2031647a',\n",
    "                        \"incorrect value for sampleOHEDictManual[(1,'tabby')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(2,'mouse')],\n",
    "                        'ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4',\n",
    "                        \"incorrect value for sampleOHEDictManual[(2,'mouse')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(2,'salmon')],\n",
    "                        'c1dfd96eea8cc2b62785275bca38ac261256e278',\n",
    "                        \"incorrect value for sampleOHEDictManual[(2,'salmon')]\")\n",
    "Test.assertEquals(len(sampleOHEDictManual.keys()), 7,\n",
    "                  'incorrect number of keys in sampleOHEDictManual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Sparse vectors **\n",
    "#### Data points can typically be represented with a small number of non-zero OHE features relative to the total number of features that occur in the dataset.  By leveraging this sparsity and using sparse vector representations of OHE data, we can reduce storage and computational burdens.  Below are a few sample vectors represented as dense numpy arrays.  Use [SparseVector](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector) to represent them in a sparse fashion, and verify that both the sparse and dense representations yield the same results when computing [dot products](http://en.wikipedia.org/wiki/Dot_product) (we will later use MLlib to train classifiers via gradient descent, and MLlib will need to compute dot products between SparseVectors and dense parameter vectors).\n",
    "#### Use `SparseVector(size, *args)` to create a new sparse vector where size is the length of the vector and args is either a dictionary, a list of (index, value) pairs, or two separate arrays of indices and values (sorted by index).  You'll need to create a sparse vector representation of each dense vector `aDense` and `bDense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3\n",
      "7.3\n",
      "-0.5\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "aDense = np.array([0., 3., 0., 4.])\n",
    "#aSparse = <FILL IN>\n",
    "aSparse = SparseVector(4,[1,3],[3.,4.])\n",
    "\n",
    "bDense = np.array([0., 0., 0., 1.])\n",
    "#bSparse = <FILL IN>\n",
    "bSparse = SparseVector(4,[3],[1.])\n",
    "\n",
    "w = np.array([0.4, 3.1, -1.4, -.5])\n",
    "print aDense.dot(w)\n",
    "print aSparse.dot(w)\n",
    "print bDense.dot(w)\n",
    "print bSparse.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Sparse Vectors (1b)\n",
    "Test.assertTrue(isinstance(aSparse, SparseVector), 'aSparse needs to be an instance of SparseVector')\n",
    "Test.assertTrue(isinstance(bSparse, SparseVector), 'aSparse needs to be an instance of SparseVector')\n",
    "Test.assertTrue(aDense.dot(w) == aSparse.dot(w),\n",
    "                'dot product of aDense and w should equal dot product of aSparse and w')\n",
    "Test.assertTrue(bDense.dot(w) == bSparse.dot(w),\n",
    "                'dot product of bDense and w should equal dot product of bSparse and w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) OHE features as sparse vectors **\n",
    "#### Now let's see how we can represent the OHE features for points in our sample dataset.  Using the mapping defined by the OHE dictionary from Part (1a), manually define OHE features for the three sample data points using SparseVector format.  Any feature that occurs in a point should have the value 1.0.  For example, the `DenseVector` for a point with features 2 and 4 would be `[0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reminder of the sample features\n",
    "# sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "# sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "# sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "#sampleOneOHEFeatManual = <FILL IN>\n",
    "sampleOneOHEFeatManual = SparseVector(7,[2,3],[1.,1.]) # [0.,0.,1.,1.,0.,0.,0.]\n",
    "sampleTwoOHEFeatManual = SparseVector(7,[1,4,5],[1.,1.,1.])  # [0.,1.,0.,0.,1.,1.,0.]\n",
    "sampleThreeOHEFeatManual = SparseVector(7,[0,3,6],[1.,1.,1.]) # [1.,0.,0.,1.,0.,0.,1.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST OHE Features as sparse vectors (1c)\n",
    "Test.assertTrue(isinstance(sampleOneOHEFeatManual, SparseVector),\n",
    "                'sampleOneOHEFeatManual needs to be a SparseVector')\n",
    "Test.assertTrue(isinstance(sampleTwoOHEFeatManual, SparseVector),\n",
    "                'sampleTwoOHEFeatManual needs to be a SparseVector')\n",
    "Test.assertTrue(isinstance(sampleThreeOHEFeatManual, SparseVector),\n",
    "                'sampleThreeOHEFeatManual needs to be a SparseVector')\n",
    "Test.assertEqualsHashed(sampleOneOHEFeatManual,\n",
    "                        'ecc00223d141b7bd0913d52377cee2cf5783abd6',\n",
    "                        'incorrect value for sampleOneOHEFeatManual')\n",
    "Test.assertEqualsHashed(sampleTwoOHEFeatManual,\n",
    "                        '26b023f4109e3b8ab32241938e2e9b9e9d62720a',\n",
    "                        'incorrect value for sampleTwoOHEFeatManual')\n",
    "Test.assertEqualsHashed(sampleThreeOHEFeatManual,\n",
    "                        'c04134fd603ae115395b29dcabe9d0c66fbdc8a7',\n",
    "                        'incorrect value for sampleThreeOHEFeatManual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1d) Define a OHE function **\n",
    "#### Next we will use the OHE dictionary from Part (1a) to programatically generate OHE features from the original categorical data.  First write a function called `oneHotEncoding` that creates OHE feature vectors in `SparseVector` format.  Then use this function to create OHE features for the first sample data point and verify that the result matches the result from Part (1c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,[2,3],[1.0,1.0])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n",
    "        OHEDict (dict): A mapping of (featureID, value) to unique integer.\n",
    "        numOHEFeats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    #<FILL IN>\n",
    "    \n",
    "    ##\n",
    "    ## THIS IS THE FIRST VERSION\n",
    "    ## It works but is very inefficient...\n",
    "    ##\n",
    "    #lenRaw = len(rawFeats)\n",
    "    #a = [0]*lenRaw\n",
    "    #b = [0]*lenRaw\n",
    "    #i = -1\n",
    "    #for x in rawFeats:\n",
    "    #    valAux = int(OHEDict[x])\n",
    "    #    i += 1\n",
    "    #    a[i] = int(valAux)\n",
    "    #    b[i] = 1.\n",
    "    #a = np.sort(a)\n",
    "    \n",
    "    ## Better version !!!\n",
    "    \n",
    "    a = [int(OHEDict[x]) for x in rawFeats]\n",
    "    a = np.sort(a)\n",
    "    b = [1. for x in rawFeats]\n",
    "    \n",
    "    return SparseVector(numOHEFeats,a,b)\n",
    "\n",
    "# Calculate the number of features in sampleOHEDictManual\n",
    "numSampleOHEFeats = len(sampleOHEDictManual)\n",
    "\n",
    "# Run oneHotEnoding on sampleOne\n",
    "sampleOneOHEFeat = oneHotEncoding(sampleOne, sampleOHEDictManual, len(sampleOHEDictManual))\n",
    "\n",
    "print sampleOneOHEFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Define an OHE Function (1d)\n",
    "Test.assertTrue(sampleOneOHEFeat == sampleOneOHEFeatManual,\n",
    "                'sampleOneOHEFeat should equal sampleOneOHEFeatManual')\n",
    "Test.assertEquals(sampleOneOHEFeat, SparseVector(7, [2,3], [1.0,1.0]),\n",
    "                  'incorrect value for sampleOneOHEFeat')\n",
    "Test.assertEquals(oneHotEncoding([(1, 'black'), (0, 'mouse')], sampleOHEDictManual,\n",
    "                                 numSampleOHEFeats), SparseVector(7, [2,3], [1.0,1.0]),\n",
    "                  'incorrect definition for oneHotEncoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1e) Apply OHE to a dataset **\n",
    "#### Finally, use the function from Part (1d) to create OHE features for all 3 data points in the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseVector(7, {2: 1.0, 3: 1.0}), SparseVector(7, {1: 1.0, 4: 1.0, 5: 1.0}), SparseVector(7, {0: 1.0, 3: 1.0, 6: 1.0})]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOHEData = sampleDataRDD.map(lambda x: oneHotEncoding(x, sampleOHEDictManual, len(sampleOHEDictManual)))\n",
    "print sampleOHEData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Apply OHE to a dataset (1e)\n",
    "sampleOHEDataValues = sampleOHEData.collect()\n",
    "Test.assertTrue(len(sampleOHEDataValues) == 3, 'sampleOHEData should have three elements')\n",
    "Test.assertEquals(sampleOHEDataValues[0], SparseVector(7, {2: 1.0, 3: 1.0}),\n",
    "                  'incorrect OHE for first sample')\n",
    "Test.assertEquals(sampleOHEDataValues[1], SparseVector(7, {1: 1.0, 4: 1.0, 5: 1.0}),\n",
    "                  'incorrect OHE for second sample')\n",
    "Test.assertEquals(sampleOHEDataValues[2], SparseVector(7, {0: 1.0, 3: 1.0, 6: 1.0}),\n",
    "                  'incorrect OHE for third sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 2: Construct an OHE dictionary **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) Pair RDD of `(featureID, category)` **\n",
    "#### To start, create an RDD of distinct `(featureID, category)` tuples. In our sample dataset, the 7 items in the resulting RDD are `(0, 'bear')`, `(0, 'cat')`, `(0, 'mouse')`, `(1, 'black')`, `(1, 'tabby')`, `(2, 'mouse')`, `(2, 'salmon')`. Notably `'black'` appears twice in the dataset but only contributes one item to the RDD: `(1, 'black')`, while `'mouse'` also appears twice and contributes two items: `(0, 'mouse')` and `(2, 'mouse')`.  Use [flatMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.flatMap) and [distinct](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.distinct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'mouse'), (0, 'cat'), (0, 'bear'), (2, 'salmon'), (1, 'tabby'), (1, 'black'), (0, 'mouse')]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleDistinctFeats = (sampleDataRDD\n",
    "                       .flatMap(lambda x: x).distinct()) #.map(lambda x: (x[0],x[1])))\n",
    "print sampleDistinctFeats.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Pair RDD of (featureID, category) (2a)\n",
    "Test.assertEquals(sorted(sampleDistinctFeats.collect()),\n",
    "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
    "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
    "                  'incorrect value for sampleDistinctFeats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2b) OHE Dictionary from distinct features **\n",
    "#### Next, create an `RDD` of key-value tuples, where each `(featureID, category)` tuple in `sampleDistinctFeats` is a key and the values are distinct integers ranging from 0 to (number of keys - 1).  Then convert this `RDD` into a dictionary, which can be done using the `collectAsMap` action.  Note that there is no unique mapping from keys to values, as all we require is that each `(featureID, category)` key be mapped to a unique integer between 0 and the number of keys.  In this exercise, any valid mapping is acceptable.  Use [zipWithIndex](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.zipWithIndex) followed by [collectAsMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collectAsMap).\n",
    "#### In our sample dataset, one valid list of key-value tuples is: `[((0, 'bear'), 0), ((2, 'salmon'), 1), ((1, 'tabby'), 2), ((2, 'mouse'), 3), ((0, 'mouse'), 4), ((0, 'cat'), 5), ((1, 'black'), 6)]`. The dictionary defined in Part (1a) illustrates another valid mapping between keys and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 'mouse'): 0, (0, 'cat'): 1, (0, 'bear'): 2, (2, 'salmon'): 3, (1, 'tabby'): 4, (1, 'black'): 5, (0, 'mouse'): 6}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOHEDict = (sampleDistinctFeats\n",
    "                           .zipWithIndex().collectAsMap())\n",
    "print sampleOHEDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST OHE Dictionary from distinct features (2b)\n",
    "Test.assertEquals(sorted(sampleOHEDict.keys()),\n",
    "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
    "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
    "                  'sampleOHEDict has unexpected keys')\n",
    "Test.assertEquals(sorted(sampleOHEDict.values()), range(7), 'sampleOHEDict has unexpected values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) Automated creation of an OHE dictionary **\n",
    "#### Now use the code from Parts (2a) and (2b) to write a function that takes an input dataset and outputs an OHE dictionary.  Then use this function to create an OHE dictionary for the sample dataset, and verify that it matches the dictionary from Part (2b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 'mouse'): 0, (0, 'cat'): 1, (0, 'bear'): 2, (2, 'salmon'): 3, (1, 'tabby'): 4, (1, 'black'): 5, (0, 'mouse'): 6}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def createOneHotDict(inputData):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "\n",
    "    Args:\n",
    "        inputData (RDD of lists of (int, str)): An RDD of observations where each observation is\n",
    "            made up of a list of (featureID, value) tuples.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    return inputData.flatMap(lambda x: x).distinct().zipWithIndex().collectAsMap()\n",
    "\n",
    "sampleOHEDictAuto = createOneHotDict(sampleDataRDD)\n",
    "print sampleOHEDictAuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Automated creation of an OHE dictionary (2c)\n",
    "Test.assertEquals(sorted(sampleOHEDictAuto.keys()),\n",
    "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
    "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
    "                  'sampleOHEDictAuto has unexpected keys')\n",
    "Test.assertEquals(sorted(sampleOHEDictAuto.values()), range(7),\n",
    "                  'sampleOHEDictAuto has unexpected values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3: Parse CTR data and generate OHE features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we can proceed, you'll first need to obtain the data from Criteo.  If you have already completed this step in the setup lab, just run the cells below and the data will be loaded into the `rawData` variable.\n",
    "#### Below is Criteo's data sharing agreement.  After you accept the agreement, you can obtain the download URL by right-clicking on the \"Download Sample\" button and clicking \"Copy link address\" or \"Copy Link Location\", depending on your browser.  Paste the URL into the `# TODO` cell below.  The file is 8.4 MB compressed.  The script below will download the file to the virtual machine (VM) and then extract the data.\n",
    "#### If running the cell below does not render a webpage, open the [Criteo agreement](http://labs.criteo.com/downloads/2014-kaggle-display-advertising-challenge-dataset/) in a separate browser tab.  After you accept the agreement, you can obtain the download URL by right-clicking on the \"Download Sample\" button and clicking \"Copy link address\" or \"Copy Link Location\", depending on your browser.  Paste the URL into the `# TODO` cell below.\n",
    "#### Note that the download could take 